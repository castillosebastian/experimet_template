---
title: "basic EDA"
author: "Claudio Sebastián Castillo"
date: "`r format(Sys.Date(), '%d de %B de %Y') `"
output:
  html_document:
    df_print: paged
  html_notebook: default
---

```{r}
# https://www.kaggle.com/code/gomes555/tps-apr2021-r-eda-lightgbm-bayesopt
source(paste0(here::here(), "/main.R"))
require("tidymodels")
data = fread(paste0(PROCESSED_DATA_DIR, "/dataset_growth4.csv.gz"))
```

```{r}
conf_mat_plot <- function(x, null_model = FALSE, colclass){
  require(patchwork)
  
  trs <- 0.5
  
  if(null_model==FALSE){
    x <- x %>% 
      mutate(.pred_class = ifelse(.pred_1 >= trs, 1, 0) %>%
               factor())  
  }
  
  p1 <- 
    x %>%
    select(.pred_class, {{colclass}}) %>%
    table() %>% 
    conf_mat() %>% 
    autoplot(type = "heatmap")+
    labs(title = "Confusion Matrix",
         subtitle = paste0("Threshold: ", round(trs, 4)))
  
  p2 <- 
    x  %>%
    ggplot() +
    geom_density(aes(x = .pred_1, fill = {{colclass}}), 
                 alpha = 0.5)+
    labs(title = "Predicted probability distributions",
         subtitle = "by target")+ 
    scale_x_continuous(limits = 0:1)+
    geom_vline(aes(xintercept = trs, color = "threshold"), linetype = 2) +
    scale_color_manual(name = "", values = c(`threshold` =  "red"))+
    scale_fill_viridis_d(end = 0.7, direction = 1)
  
  p1 | p2
}

```


```{r}
skimr::skim(data)
```
# data formating


```{r}
# date_cols <- c("fini_sintomas", "finternacion", "fdiag_covid")
# setDT(data)[, (date_cols) := lapply(.SD, lubridate::ymd), .SDcols = date_cols]
# setDT(data)[, (date_cols) := lapply(.SD, format, "%Y%m"), .SDcols = date_cols]
# setDT(data)[, (date_cols) := lapply(.SD, as.numeric), .SDcols = date_cols]
```

```{r}
data[ , resultado := as.factor(resultado)]
```

```{r}
data %>% 
  #sample_n(100) %>% 
  visdat::vis_dat()
```

```{r}
data %>% 
  #sample_n(100) %>% 
  visdat::vis_miss()
```

```{r}
data %>%
  inspectdf::inspect_na() %>% 
  inspectdf::show_plot()
```


```{r}
data[, c("ldh", "progr_imagerad_perc"):=NULL]  # remove two columns
```



```{r}
data %>% 
  naniar::gg_miss_upset()
```

```{r}
data %>% as_tibble() %>% 
  select_if(is.numeric) %>% 
  visdat::vis_cor()
```

```{r}
data %>% as_tibble() %>%
  select_if(~!is.numeric(.)) %>%
  inspectdf::inspect_cat() %>% 
  inspectdf::show_plot()
```
# Factor class

```{r}
data$resultado = as.factor(data$resultado)
```


# Null Model

```{r}
#https://www.tidymodels.org/start/recipes/
set.seed(314)
split <-  rsample::initial_split(data = data, strata = resultado,    prop = 0.8)

covidtrain = training(split)
covidtest = testing(split)

```


```{r}
covid_recipe <- recipes::recipe(resultado ~ ., data = covidtrain) %>% 
  #update_role(codigo_paciente, new_role = "ID") %>% 
  # step_medianimpute(all_predictors())
  # step_date(finternacion, features = c("dow", "month")) %>%               
  # step_holiday(finternacion, 
  #              holidays = timeDate::listHolidays("Argentina"),
  #              keep_original_cols = FALSE) %>%
  #step_dummy(all_nominal_predictors()) %>% 
  #step_impute_linear(all_predictors()) %>% 
  #step_dummy(all_nominal_predictors()) %>% 
  #step_zv(all_predictors())
  prep()
```


```{r}
folds <-  recipes::bake(covid_recipe, new_data = covidtrain) %>%
  rsample::vfold_cv(v = 4)
```


# Null Accuracy Model

```{r}
null_model <- null_model(mode = "classification") %>% 
  set_engine("parsnip")

null_wflow_bas <- workflow() %>% 
  add_recipe(covid_recipe) %>% 
  add_model(null_model) 

null_final_fit_bas <- null_wflow_bas %>% last_fit(split) 

null_test_preds_bas <- collect_predictions(null_final_fit_bas)

null_test_preds_bas %>% 
  conf_mat_plot(colclass = resultado, null_model = T)
```


# LigthGBM


```{r}
library(parsnip)
library(treesnip)
xgb_model_bas <- boost_tree(
    trees = 200,       # num_iterations
    learn_rate = 0.3,  # eta
    min_n = 20,        # min_data_in_leaf
    #tree_depth = 6,   # max_depth
    sample_size = 1,   # bagging_fraction
    mtry = 1,          # feature_fraction
    loss_reduction = 0 # min_gain_to_split
) %>%  
  set_engine("lightgbm", num_leaves = 31) %>% 
  set_mode("classification")

xgb_wflow_bas <- workflow() %>% 
  add_recipe(covid_recipe) %>% 
  add_model(xgb_model_bas) 

xgb_res_bas <- fit_resamples(
  xgb_wflow_bas,
  folds,
  metrics = metric_set(accuracy),
  control = control_resamples(save_pred = FALSE)
)

xgb_final_fit_bas <- xgb_wflow_bas %>% last_fit(split) 

xgb_test_preds_bas <- collect_predictions(xgb_final_fit_bas)

xgb_test_preds_bas %>% 
  conf_mat_plot( null_model = F, colclass = resultado)
```

# Bayesian Optimization and GBM

```{r}
doParallel::registerDoParallel(4)
```

```{r}
# Model especification
lightgbm_model<-
  parsnip::boost_tree(
    mode = "regression",
    trees = 1000,
    learn_rate = 0.01,
    min_n = tune(),
    tree_depth = tune()#,
    #loss_reduction = tune(),
    #sample_size = tune()
  ) %>%
  set_engine("lightgbm", num_leaves = 31) %>% 
  set_mode("classification")
```

```{r}
lightgbm_params <-
  dials::parameters(
    # The parameters have sane defaults, but if you have some knowledge 
    # of the process you can set upper and lower limits to these parameters.
   min_n(), # 2nd important
   tree_depth() # 3rd most important
  )

```

```{r}
lgbm_grid <-
  dials::grid_max_entropy(
    lightgbm_params,
    size = 60 # set this to a higher number to get better results
    # I don't want to run this all night, so I set it to 30
  )
head(lgbm_grid)

lgbm_wf <-
  workflows::workflow() %>%
  add_model(lightgbm_model
  ) %>%
  add_formula(resultado ~ .)


```

```{r}
lgbm_tuned <- tune::tune_grid(
  object = lgbm_wf,
  resamples = folds,
  grid = lgbm_grid,
  metrics =  metric_set(accuracy),
  control = tune::control_grid(verbose = T) # set this to TRUE to see
  # in what step of the process you are. But that doesn't look that well in
  # a blog.
)
```


```{r}
show_best(lgbm_tuned, metric = 'accuracy')
```

```{r}
lgbm_final_wflow_tun <- 
  finalize_workflow(
    lgbm_wf,
    select_best(lgbm_tuned, metric = 'accuracy') )

lgbm_final_fit_tun <- lgbm_final_wflow_tun %>% last_fit(split) 

lgbm_test_preds_tun <- collect_predictions(lgbm_final_fit_tun)

lgbm_test_preds_tun %>% 
  conf_mat_plot(null_model = F, colclass = resultado)
```
```{r}
# https://www.r-bloggers.com/2020/08/how-to-use-lightgbm-with-tidymodels/
# quedó en Find the best model from tuning results
```








